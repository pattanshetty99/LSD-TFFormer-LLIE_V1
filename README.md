# LSD-TFFormer-LLIE_V1

## Low-Light Image Enhancement using Hierarchical Swin Transformer with LayerScale and DropPath

---

## ğŸ“Œ Overview

**LSD-TFFormer-LLIE** is a hierarchical Transformer-based deep learning model designed for **Low-Light Image Enhancement (LLIE)**.

This implementation includes:

- âœ… 512Ã—512 full-resolution training
- âœ… Hierarchical Encoderâ€“Decoder architecture
- âœ… Swin-style Window Attention with Shifted Windows
- âœ… LayerScale stabilization
- âœ… DropPath (Stochastic Depth)
- âœ… Multi-loss training (L1 + SSIM + Perceptual)
- âœ… Automatic Mixed Precision (AMP)
- âœ… Cosine Learning Rate Scheduler
- âœ… PSNR & SSIM evaluation pipeline
- âœ… Test image inference & saving

The architecture is designed for high-resolution enhancement tasks and is optimized for modern GPUs.

---

## ğŸ§  Model Architecture

### Resolution Flow

| Stage | Resolution |
|-------|------------|
| Input | 512 Ã— 512 |
| Encoder Down1 | 256 Ã— 256 |
| Encoder Down2 | 128 Ã— 128 |
| Transformer Bottleneck | 128 Ã— 128 |
| Decoder Up1 | 256 Ã— 256 |
| Output | 512 Ã— 512 |

### Key Features

- **Swin-style Window Attention**
- **Shifted Window Mechanism**
- **LayerNorm (Pre-Norm)**
- **LayerScale for stable deep training**
- **DropPath regularization**
- **Skip Connections (U-Net style)**

---

## ğŸ“‚ Project Structure

```
LSD-TFFormer-LLIE/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lsd_tf_former.py
â”‚   â”œâ”€â”€ swin_blocks.py
â”‚   â”œâ”€â”€ layers.py
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ llie_dataset.py
â”‚
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ perceptual.py
â”‚   â”œâ”€â”€ ssim.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ checkpoint.py
â”‚   â”œâ”€â”€ scheduler.py
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ validate.py
â”œâ”€â”€ test.py
â”œâ”€â”€ evaluation.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/LSD-TFFormer-LLIE_V1.git
cd LSD-TFFormer-LLIE
```

### 2ï¸âƒ£ Install PyTorch (CUDA Recommended)

Example for CUDA 12.1:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Dataset Structure

Organize dataset as:

```
data/
â”‚
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ low/
â”‚   â””â”€â”€ high/
â”‚
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ low/
â”‚   â””â”€â”€ high/
â”‚
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ low/
â”‚   â””â”€â”€ high/
```

Each low-light image must have a corresponding ground-truth image with the same filename.

---

## ğŸš€ Training

Edit `config.py` if needed.

Start training:

```bash
python train.py
```

During training:
- Best model saved in `checkpoints/best.pth`
- PSNR displayed per epoch

---

## ğŸ§ª Validation

Validation runs automatically during training.

Standalone validation:

```bash
python validate.py
```

---

## ğŸ” Testing (Inference Only)

To enhance test images:

```bash
python test.py
```

Enhanced images will be saved in:

```
results/
```

---

## ğŸ“ˆ Evaluation (PSNR + SSIM)

To compute quantitative metrics:

```bash
python evaluation.py
```

Output:

```
Average PSNR: XX.XXX dB
Average SSIM: X.XXXX
```

---

## ğŸ— Training Configuration

Default configuration (config.py):

- Resolution: 512Ã—512
- Batch Size: 2
- Epochs: 250
- Optimizer: AdamW
- Learning Rate: 2e-4
- Scheduler: CosineAnnealingLR
- Loss:
  - L1
  - SSIM
  - LPIPS (Perceptual)

---

## ğŸ“¦ Requirements

See `requirements.txt`

Main dependencies:

- torch
- torchvision
- opencv-python
- numpy
- scikit-image
- lpips
- tqdm

---

## ğŸ’¡ Advanced Features Included

- Swin-style shifted window attention
- LayerScale for stable deep networks
- DropPath for better generalization
- Hierarchical Transformer design
- Memory-efficient bottleneck at 128Ã—128

---

## ğŸ”® Future Improvements

- Multi-stage transformer refinement
- Frequency-domain loss
- GAN-based enhancement
- NTIRE competition tuning
- Large-scale dataset training

---

## ğŸ“œ License

This project is released for research and academic purposes.

---

## ğŸ™Œ Acknowledgments

Inspired by hierarchical Transformer-based image restoration frameworks and Swin Transformer architecture principles.

---

## ğŸ‘©â€ğŸ’» Author

Your Name  
GitHub: https://github.com/yourusername

---

If you use this repository for research, please consider citing appropriately.

